# -*- coding: utf-8 -*-
"""interface.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m3AsFRknW0punAzrQfpVwqlmy_E1ftEn
"""
# import socket

print("importing libraries")
from email import message
import torch
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
from mnist import MNIST
# from multiprocessing import Process
import torch.multiprocessing as multiprocessing
from torch.multiprocessing import Process
import numpy as np
import math

np.random.seed(0)

print("downloading mnist")
mndata = MNIST('data/')
IMAGES_TRAIN, LABELS_TRAIN = mndata.load_training()
IMAGES_TEST, LABELS_TEST = mndata.load_testing()
IMAGES_TRAIN = np.asarray(IMAGES_TRAIN).reshape((-1, 1, 28, 28))
np.random.shuffle(IMAGES_TRAIN)
IMAGES_TEST = np.asarray(IMAGES_TEST).reshape((-1, 1, 28, 28))

class CNN(nn.Module): #random CNN found from online
    def __init__(self):
        # Cindy: not sure if Net is missing, plz check
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(256, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):

        # x = self.pool(F.relu(self.conv1(x)))
        x = F.relu(x)
        x = self.conv1(x)
        x = F.relu(x)
        x = self.pool(x)

        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1) # flatten all dimensions except batch
        # print("x shape step 1: ", x.shape)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# cindy
class Client():
  def __init__(self, uid, replica_group_id, queue, bsz=32, epochs=20, indices=[0, 50]): #todo: fix initialization (get data, initialize model). port #?
    
    self.uid = uid
    self.replica_group_id = replica_group_id
    self.queue = queue
    
    # MODEL
    self.model = CNN() 

    # TRAINING HYPERPARAMETERS
    self.bsz = bsz
    self.num_epochs = epochs
    # SGD inputs
    self.random_seed = 0
    self.lr = 0.01
    self.momentum = 0
    self.weight_decay = 0
    self.dampening = 0
    self.nesterov = False
    self.maximize = False
    self.optimizer = optim.SGD(self.model.parameters(), lr = self.lr, momentum = self.momentum, weight_decay = self.weight_decay, dampening = self.dampening, nesterov = self.nesterov)



    # DATA
    self.train_partititon = IMAGES_TRAIN[indices[0]:indices[1]]
    self.label_partition = LABELS_TRAIN[indices[0]:indices[1]]
    # self.train_set = torch.utils.data.DataLoader(self.train_partititon, batch_size=bsz, shuffle=True)
    # self.test_set = None
  
  def copy():
    return None

  # train local round 
  # added model bc need inplace modification for multiprocessing - Neha
  def train(self, round_num):
    # sgd algo
    
    # torch.manual_seed(self.random_seed)
    if (round_num != 0):
      # updated_parameters = self.queue.get().content
      # with torch.no_grad():
      #   counter = 0
      #   for param in self.model.parameters():
      #     # param = updated_parameters[counter]
      #     param.copy_(updated_parameters[counter])
      #     counter += 1
      with torch.no_grad():  
        updated_parameters = self.queue.get().content
        self.model.load_state_dict(updated_parameters)
        # print("client ", self.uid, "recieving weights: ", updated_parameters["conv1.weight"])
    
    train_accuracies = []
    for i in range(int(math.ceil(len(self.train_partititon)/self.bsz))):
      data = torch.tensor(self.train_partititon[i * self.bsz: min((i+1) * self.bsz, len(self.train_partititon))]).float()
      target = torch.tensor(self.label_partition[i * self.bsz: min((i+1) * self.bsz, len(self.train_partititon))]).float()
      with torch.no_grad():
        output = self.model(data).float()
        accuracy = torch.sum(torch.argmax(output, dim=1) == target) / (1.0 * len(target))
        train_accuracies.append(accuracy)

    print("training accuracy before loading model: ", np.mean(np.asarray(train_accuracies)))
      

    
    # print("client ", self.uid, "training with weights: ", self.model.state_dict()["conv1.weight"])
    losses = []
    accuracies = []
    for e in range(self.num_epochs):
      # print("epoch ", e)
      epoch_loss = 0.0

      for i in range(int(math.ceil(len(self.train_partititon)/self.bsz))):
        data = torch.tensor(self.train_partititon[i * self.bsz: min((i+1) * self.bsz, len(self.train_partititon))]).float()
        target = torch.tensor(self.label_partition[i * self.bsz: min((i+1) * self.bsz, len(self.train_partititon))]).float()
        # target = F.one_hot(target.to(torch.int64), 10).float()
        
        
        self.optimizer.zero_grad()
        # print("about to run model forward on batch")
        output = self.model(data).float()
        # print("getting loss")
        loss_fn = nn.CrossEntropyLoss()
        loss = loss_fn(output.float(), target.type(torch.LongTensor))
        epoch_loss += loss.item()
        loss.backward()
        self.optimizer.step()
        losses.append(epoch_loss)
        with torch.no_grad():
          accuracy = torch.sum(torch.argmax(output, dim=1) == target) / (1.0 * len(target))
          accuracies.append(accuracy)
    
    print("client uid finished training: ", self.uid, " training loss: ", np.mean(np.asarray(losses)), " training acc: ", np.mean(np.asarray(accuracies)))

    with torch.no_grad():
      model = self.model
      test_preds = torch.argmax(model(torch.tensor(IMAGES_TEST).float()), dim=1)
      test_labels = torch.tensor(LABELS_TEST)
      accuracy = torch.sum(test_preds == test_labels) / (1.0 * len(test_labels))
      print("test accuracy ", accuracy)

    # parameters_to_send = []
    # for parameter in self.model.parameters():
    #   parameters_to_send.append(parameter.data.detach())
    self.send_message(Message(content=self.model.state_dict(), round_num=round_num))
  
  #send message to server
  def send_message(self, msg):
    #execute the random delay
    # print("sending message from client ", self.uid)
    # print("client ", self.uid, "sending weights: ", msg.content["conv1.weight"])
    self.queue.put(msg)

  #recieve aggregated model from server
  def receive_message(self):
    pass

    # print ("client ", self.uid, " recieving message from server")
    # og_params = list(self.model.parameters()).copy()
    # og_data = torch.clone(list(self.model.parameters())[0].data)

    # og_params = []
    # for param in self.model.parameters():
    #   curr_og_param = torch.clone(param.data)
    #   og_params.append(curr_og_param)
    
    # # print("receieve message: ", og_data == param.data)

    # with torch.no_grad():  
    #   updated_parameters = self.queue.get().content
    #   self.model.load_state_dict(updated_parameters)

    # print("client ", self.uid, "recieved weights: ", updated_parameters["conv1.weight"])

    # new_params = []
    # for param in self.model.parameters():
    #   curr_new_param = torch.clone(param.data)
    #   new_params.append(curr_new_param)
    
    # all_params_diff = True
    # for i in range(len(og_params)):
    #   curr_bool = torch.all(og_params[i]==new_params[i])
    #   all_params_diff = all_params_diff and not(curr_bool)
    # print("recieve message equality :", all_params_diff)


    # print("client ", self.uid, "update weights: ", self.model.state_dict()["conv1.weight"])
    
    
    # print(og_params == list(self.model.parameters()))


class Server: #todo: send indices of data to client
  def __init__(self):
    self.client_id_to_metadata_dict = {} 
    #client_id_to_metadata_dict[client_uid] = (client object, replica_group_id)

    self.replica_group_id_to_client_uids = {}
    #replica_id_to_client_copy[replica_group_id] = (primary client uid, [client uids corresponding to this replica_group])

    self.latest_client_uid = 1025 #non priviliged ports are > 1023
    self.latest_replica_group_id = 0

  #replica_id is specified if this new client is spawned to be a replica of group replica_id. Otherwise, None
  #returns new client uid
  def spawn_new_client(self, make_replica = False, replica_group_id = None, replica_client_uid = None, data_ind_if_not_replica = None): #TODO 
    self.latest_client_uid += 1
    if make_replica:
      #assign new client the exact copy of original client 
      self.client_id_to_metadata_dict[self.latest_client_uid] = (self.client_id_to_metadata_dict[replica_client_uid][0].copy(), replica_group_id) #TODO client .copy()

      #add new client to replica data
      self.replica_group_id_to_client_uids[replica_group_id][1].append(self.latest_client_uid)
    else:
      self.latest_replica_group_id += 1
      new_client_q = multiprocessing.Queue()
      new_client = Client(self.latest_client_uid,self.latest_replica_group_id, new_client_q, indices=data_ind_if_not_replica)
      self.client_id_to_metadata_dict[self.latest_client_uid] = (new_client, self.latest_replica_group_id) 

    return self.client_id_to_metadata_dict[self.latest_client_uid][0]

  #write code to have the weights from clients collected in organized fashion
  #messages = [Message]
  def aggregate(self, messages, weights): #aggregate local training rounds (Averaging) 
    assert(len(messages) > 0)
    if len(messages) == 1:
      return messages[0].content
    else:
      for i in range(1, len(messages)):
        for k,v in messages[i].content.items():
          messages[0].content[k] += (weights[i] * v)
      for k,v in messages[0].content.items():
        messages[0].content[k] = messages[0].content[k] / len(messages)
      return messages[0].content



    # return messages[0].content

    assert(len(messages) > 0)
    
    num_parameters = len(messages[0].content)
    assert(num_parameters > 0)

    
    msg_sum = [None for i in range(num_parameters)] #list of size message_curr.content
    # with torch.no_grad():
    for message_curr_i in range(len(messages)):
      message_curr = messages[message_curr_i]
      if msg_sum[0] is None:
        for i in range(num_parameters):
          msg_sum[i] = message_curr.content[i].data
      else:
        for i in range(num_parameters):
          msg_sum[i] += weights[message_curr_i] * message_curr.content[i]
  
    
    for i in range(num_parameters):
      msg_sum[i] = msg_sum[i] / len(messages)
    return msg_sum

  #server sends 1
  def send_message(self, client, message):
    # for (client, _) in self.client_id_to_metadata_dict.values():
    # print("server sending message to client ", client.uid)
    client.queue.put(message)
  
  def receive_message(self, client): #waits for the next recieved message, times out after a point
    msg = client.queue.get()
    # print("server recieved msg  from ", client.uid)
    return msg
  



# Neha
class Message:

  def __init__(self, content, round_num = 0, sender=None, receiver=None):
    self.content = content #numpy array of weights
    self.round_num = round_num

class RunTraining: #TODO: training and stuff seems sequential ...... that's bad 
#TODO: make sure that it's not the same paramters being passed around ..........

  def __init__(self, num_clients, num_rounds=1):
    self.s = Server()
    self.clients = []
    self.client_to_process_dict= {}
    self.num_rounds = num_rounds

    NUM_TRAINING_POINTS = 60000
    num_training_per_client = NUM_TRAINING_POINTS // num_clients

    for i in range(num_clients):
      curr_client_idxs = [i * num_training_per_client, (i + 1) * num_training_per_client]
      curr_client = self.s.spawn_new_client(data_ind_if_not_replica=curr_client_idxs)
      self.clients.append(curr_client)

  def run_tasks(self, running_tasks):
    for running_task in running_tasks:
          running_task.start()
    for running_task in running_tasks: #do some straggler handling here
        running_task.join()
  
  def get_accuracy(self):
    with torch.no_grad():
      model = self.clients[0].model
      test_preds = torch.argmax(model(torch.tensor(IMAGES_TEST).float()), dim=1)
      test_labels = torch.tensor(LABELS_TEST)
      accuracy = torch.sum(test_preds == test_labels) / (1.0 * len(test_labels))
      print("accuracy: ", accuracy)
      return accuracy


  def forward(self):
    # print("called forward")

    model_parameters = None #averaged model

    for round_num in range(self.num_rounds): #num global rounds

      #train a round of clients in parallel
      # print("train a round of clients in parallel")
      running_tasks = []
      for client in self.clients:
        running_tasks.append(Process(target=client.train, args=(round_num,)))
      self.run_tasks(running_tasks)

      #server receives trained models from each client
      # print("server receives trained models from each client")
      messages = []
      for client in self.clients:
        messages.append(self.s.receive_message(client))

      #aggregate models
      # print("aggregate models")
      # print("mdoel parameters example: ", messages[0].content)
      # print("mdoel parameters example: ", len(messages[0].content))
      model_parameters = self.s.aggregate(messages, [1 for msg in messages])

      #server sends new model to all clients in parallel
      # print("server sends new model to all clients in parallel")
      running_tasks = []
      for client in self.clients:
        running_tasks.append(Process(target=self.s.send_message, args=(client, Message(content=model_parameters, round_num=round_num))))
      self.run_tasks(running_tasks)

      #client saves new model
      # print("client saves new model")
      running_tasks = []
      for client in self.clients:
        running_tasks.append(Process(target=client.receive_message))
      self.run_tasks(running_tasks)
      
      # return model_parameters
      # self.get_accuracy()
      print("\n")

def main():
  runner = RunTraining(2, num_rounds=5) #comment
  runner.forward()
  print("final accuracy: ")
  runner.get_accuracy()

if __name__ == '__main__':
    main()


